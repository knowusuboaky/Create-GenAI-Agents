{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library of LangAgent\n",
    "#pip install LangAgent==0.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import agents from all teams\n",
    "#from LangAgent import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## API Keys\n",
    "import yaml\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "\n",
    "\n",
    "PATH_CREDENTIALS = 'credentials.yml'\n",
    "\n",
    "# Load API keys\n",
    "GROQ_API_KEY = yaml.safe_load(open('credentials.yml'))['groq']\n",
    "os.environ['TAVILY_API_KEY'] = yaml.safe_load(open('credentials.yml'))['online']\n",
    "os.environ['OPENWEATHERMAP_API_KEY'] = yaml.safe_load(open('credentials.yml'))['weather']\n",
    "os.environ[\"OPENAI_API_KEY\"] = yaml.safe_load(open('credentials.yml'))['openai']\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "llm = ChatOpenAI(model=MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Researcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangAgent/research_team/agents/researcher\n",
    "from LangAgent.research_team.agents import researcher\n",
    "\n",
    "import yaml\n",
    "os.environ['TAVILY_API_KEY'] = yaml.safe_load(open('credentials.yml'))['online']\n",
    "\n",
    "search = {\n",
    "    'api_key': os.environ.get(\"TAVILY_API_KEY\"),\n",
    "    'max_results': 5,\n",
    "    'search_depth': \"advanced\"\n",
    "}\n",
    "researcher_agent = researcher(llm=llm, tavily_search=search) ##try researcher.researcher(llm, tavily_search=search) if errors\n",
    "\n",
    "question = \"\"\" \n",
    "Who is Figo?\n",
    "\"\"\"\n",
    "result = researcher_agent.invoke({\"messages\": [HumanMessage(content=question)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```markdown\n",
      "**Summary**:\n",
      "Luís Figo is a retired Portuguese professional footballer widely regarded as one of the best players of his generation. He is known for his exceptional skill, vision, and ability to play on both the wing and as an attacking midfielder.\n",
      "\n",
      "**Key Facts**:\n",
      "- Born: November 4, 1972, in Almada, Portugal\n",
      "- Positions: Winger, Attacking Midfielder\n",
      "- Clubs: Sporting CP, FC Barcelona, Real Madrid, Inter Milan\n",
      "- Individual Awards: FIFA World Player of the Year (2001), Ballon d'Or runner-up (2000)\n",
      "- Major Achievements: UEFA Champions League Winner (2002), UEFA European Championship Winner (2016, as a coach).\n",
      "\n",
      "**Context**:\n",
      "Figo's career is notable for his controversial transfer from FC Barcelona to Real Madrid in 2000, which intensified the rivalry between the two clubs. He played a crucial role in the success of his teams and was a key figure in the Portuguese national team, contributing to their first major international trophy in 2016 as a part of the coaching staff.\n",
      "\n",
      "**Sources**:\n",
      "1. [Wikipedia - Luís Figo](https://en.wikipedia.org/wiki/Lu%C3%ADs_Figo)\n",
      "2. [BBC Sport - Luís Figo](https://www.bbc.com/sport/football/teams/portugal/players/lu%C3%ADs-figo)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LangAgent.research_team.agents import coder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "coder_agent = coder(llm=llm, system_prompt=None)\n",
    "\n",
    "question = \"\"\" \n",
    "Write a Python function to calculate the factorial of a number.\n",
    "\"\"\"\n",
    "\n",
    "# Ask the agent to generate code\n",
    "result = coder_agent.invoke({\"messages\": [HumanMessage(content=question)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "# Function to calculate the factorial of a number\n",
      "def factorial(n):\n",
      "    \"\"\"\n",
      "    Calculate the factorial of a non-negative integer n.\n",
      "\n",
      "    Parameters:\n",
      "    n (int): A non-negative integer whose factorial is to be calculated.\n",
      "\n",
      "    Returns:\n",
      "    int: The factorial of the number n.\n",
      "    \"\"\"\n",
      "    if n < 0:\n",
      "        raise ValueError(\"Factorial is not defined for negative numbers.\")\n",
      "    elif n == 0 or n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        result = 1\n",
      "        for i in range(2, n + 1):\n",
      "            result *= i\n",
      "        return result\n",
      "\n",
      "# Example usage\n",
      "print(factorial(5))  # Output: 120\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "The `factorial` function computes the factorial of a non-negative integer `n`. \n",
      "- If `n` is less than 0, it raises a `ValueError` since factorials are undefined for negative numbers.\n",
      "- For `n` equal to 0 or 1, it returns 1, as both 0! and 1! are equal to 1.\n",
      "- For all other positive integers, it calculates the factorial by multiplying all integers from 2 to `n` and returns the result.\n"
     ]
    }
   ],
   "source": [
    "print(result['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LangAgent.research_team.agents import weather\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "weather_agent = weather(llm, OPENWEATHERMAP_API_KEY=os.environ['OPENWEATHERMAP_API_KEY'])\n",
    "\n",
    "question = \"\"\" \n",
    "What is the weather today in New York?\n",
    "\"\"\"\n",
    "\n",
    "# Ask for weather details\n",
    "result = weather_agent.invoke({\"messages\": [HumanMessage(content=question)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's weather in New York, US is as follows:\n",
      "\n",
      "- **Condition:** Fog\n",
      "- **Temperature:** \n",
      "  - Current: 14.84°C\n",
      "  - High: 16.19°C\n",
      "  - Low: 12.97°C\n",
      "  - Feels like: 14.68°C\n",
      "- **Wind Speed:** 0 m/s\n",
      "- **Humidity:** 88%\n",
      "- **Cloud Cover:** 40%\n",
      "\n",
      "There is no rain expected today.\n"
     ]
    }
   ],
   "source": [
    "print(result['output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
